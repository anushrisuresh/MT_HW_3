#!/usr/bin/env python
import optparse
import sys
import models
from collections import namedtuple
from tqdm import tqdm

# Parse command-line arguments
optparser = optparse.OptionParser()
optparser.add_option("-i", "--input", dest="input", default="data/input", help="File containing sentences to translate (default=data/input)")
optparser.add_option("-t", "--translation-model", dest="tm", default="data/tm", help="File containing translation model (default=data/tm)")
optparser.add_option("-l", "--language-model", dest="lm", default="data/lm", help="File containing ARPA-format language model (default=data/lm)")
optparser.add_option("-n", "--num_sentences", dest="num_sents", default=sys.maxsize, type="int", help="Number of sentences to decode (default=no limit)")
optparser.add_option("-k", "--translations-per-phrase", dest="k", default=10, type="int", help="Limit on number of translations to consider per phrase (default=1)")
optparser.add_option("-s", "--stack-size", dest="s", default=1, type="int", help="Maximum stack size (default=1)")
optparser.add_option("-b", "--beam-width", dest="beam_width", default=1000, type="int", help="Beam width for beam search decoding (default=3)")
optparser.add_option("-d", "--distortion-limit", dest="d", default=10, type="int", help="Distortion limit (default=4)")
optparser.add_option("-v", "--verbose", dest="verbose", action="store_true", default=False, help="Verbose mode (default=off)")
opts = optparser.parse_args()[0]

# Load translation model and language model
tm = models.TM(opts.tm, opts.k)
lm = models.LM(opts.lm)
french = [tuple(line.strip().split()) for line in open(opts.input).readlines()[:opts.num_sents]]

# Handle unknown words by translating them as-is
for word in set(sum(french, ())):
    if (word,) not in tm:
        tm[(word,)] = [models.phrase(word, 0.0)]

# Define the hypothesis structure to keep track of state
hypothesis = namedtuple("hypothesis", "logprob, lm_state, predecessor, phrase, coverage")

# Beam search decoding with reordering and pruning
sys.stderr.write("Decoding %s...\n" % (opts.input,))
for f in tqdm(french):
    # Initial hypothesis: no words covered, LM at the start
    initial_coverage = (False,) * len(f)
    initial_hypothesis = hypothesis(0.0, lm.begin(), None, None, initial_coverage)
    stacks = [{} for _ in range(len(f) + 1)]
    stacks[0][(lm.begin(), initial_hypothesis.coverage)] = initial_hypothesis

    # Process each stack in the beam search
    for i in range(len(f) + 1):
        current_beam = sorted(stacks[i].values(), key=lambda h: -h.logprob)[:opts.beam_width]  # Beam pruning
        for h in current_beam:
            # Try all phrase translations from all positions
            for j in range(len(f)):
                for k in range(j + 1, min(len(f), j + opts.d) + 1):
                    if any(h.coverage[z] for z in range(j,k) ):  # Skip already covered words
                        continue
                    phrase_tuple = f[j:k]
                    if phrase_tuple in tm:
                        for phrase in tm[phrase_tuple]:
                            logprob = h.logprob + phrase.logprob
                            lm_state = h.lm_state
                            
                            # Score the English words in the phrase
                            for word in phrase.english.split():
                                (lm_state, word_logprob) = lm.score(lm_state, word)
                                logprob += word_logprob

                            # Update coverage
                            new_coverage = list(h.coverage)
                            for l in range(j, k):
                                new_coverage[l] = True
                            new_coverage = tuple(new_coverage)

                            # Apply end LM score if fully covered
                            if all(new_coverage):
                                logprob += lm.end(lm_state)
                            
                            new_hypothesis = hypothesis(logprob, lm_state, h, phrase, new_coverage)
                            key = (lm_state, new_hypothesis.coverage)
                            
                            # Recombine or add hypothesis
                            if key not in stacks[sum(new_coverage)] or stacks[sum(new_coverage)][key].logprob < logprob:
                                stacks[sum(new_coverage)][key] = new_hypothesis

                            if opts.verbose:
                                sys.stderr.write(f"[DEBUG] Phrase: '{phrase.english}', Logprob: {logprob:.4f}, Coverage: {new_coverage}, LM State: {lm_state}\n")

    # Find the best hypothesis in the last stack (all words covered)
    winner = max(stacks[-1].values(), key=lambda h: h.logprob)

    # Extract the English sentence from the winning hypothesis
    def extract_english(h):
        return "" if h.predecessor is None else f"{extract_english(h.predecessor)}{h.phrase.english} "

    print(extract_english(winner))

    # Verbose mode: print log probabilities for LM and TM
    if opts.verbose:
        def extract_tm_logprob(h):
            return 0.0 if h.predecessor is None else h.phrase.logprob + extract_tm_logprob(h.predecessor)

        tm_logprob = extract_tm_logprob(winner)
        sys.stderr.write(f"LM = {winner.logprob - tm_logprob}, TM = {tm_logprob}, Total = {winner.logprob}\n")